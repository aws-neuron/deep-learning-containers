ARG BUILD_STAGE=prod

FROM public.ecr.aws/docker/library/ubuntu:22.04 AS base

LABEL dlc_major_version="1"
LABEL maintainer="Amazon AI"
LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true

ARG PIP=pip3
ARG PYTHON=python3.10
ARG PYTHON_VERSION=3.10.12
ARG TORCHSERVE_VERSION=0.11.0
ARG SM_TOOLKIT_VERSION=2.0.25
ARG MAMBA_VERSION=23.1.0-4

# See http://bugs.python.org/issue19846
ENV LANG=C.UTF-8
ENV LD_LIBRARY_PATH=/opt/aws/neuron/lib:/lib/x86_64-linux-gnu:/opt/conda/lib/:$LD_LIBRARY_PATH
ENV PATH=/opt/conda/bin:/opt/aws/neuron/bin:$PATH
ENV SAGEMAKER_SERVING_MODULE=sagemaker_pytorch_serving_container.serving:main
ENV TEMP=/home/model-server/tmp

RUN apt-get update \
 && apt-get upgrade -y \
 && apt-get install -y --no-install-recommends \
    apt-transport-https \
    build-essential \
    ca-certificates \
    cmake \
    curl \
    emacs \
    git \
    gnupg2 \
    gpg-agent \
    jq \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libcap-dev \
    libhwloc-dev \
    openjdk-11-jdk \
    unzip \
    vim \
    wget \
    zlib1g-dev \
 && rm -rf /var/lib/apt/lists/* \
 && rm -rf /tmp/tmp* \
 && apt-get clean

# https://github.com/docker-library/openjdk/issues/261 https://github.com/docker-library/openjdk/pull/263/files
RUN keytool -importkeystore -srckeystore /etc/ssl/certs/java/cacerts -destkeystore /etc/ssl/certs/java/cacerts.jks -deststoretype JKS -srcstorepass changeit -deststorepass changeit -noprompt; \
    mv /etc/ssl/certs/java/cacerts.jks /etc/ssl/certs/java/cacerts; \
    /var/lib/dpkg/info/ca-certificates-java.postinst configure;

RUN curl -L -o ~/mambaforge.sh https://github.com/conda-forge/miniforge/releases/download/${MAMBA_VERSION}/Mambaforge-${MAMBA_VERSION}-Linux-x86_64.sh \
 && chmod +x ~/mambaforge.sh \
 && ~/mambaforge.sh -b -p /opt/conda \
 && rm ~/mambaforge.sh \
 && /opt/conda/bin/conda update -y conda \
 && /opt/conda/bin/mamba install -c conda-forge -y \
    python=$PYTHON_VERSION \
    pyopenssl \
    cython \
    mkl-include \
    mkl \
    parso \
    typing \
    # Below 2 are included in miniconda base, but not mamba so need to install
    conda-content-trust \
    charset-normalizer \
 && /opt/conda/bin/conda clean -ya

RUN /opt/conda/bin/mamba install -c conda-forge \
    scikit-learn \
    h5py \
    requests \
 && conda clean -ya \
 && pip install --upgrade pip \
    --trusted-host pypi.org --trusted-host files.pythonhosted.org \
 && ln -s /opt/conda/bin/pip /usr/local/bin/pip3 \
 && pip install \
    packaging \
    enum-compat \
    ipython \
 && rm -rf ~/.cache/pip/*

RUN ${PIP} install --no-cache-dir -U \
    opencv-python>=4.8.1.78 \
    "numpy<1.24,>1.21" \
    "scipy>=1.8.0" \
    six \
    "pillow>=10.0.1" \
    "awscli<2" \
    pandas==1.* \
    boto3 \
    cryptography \
    "protobuf>=3.18.3,<4" \
    torchserve==${TORCHSERVE_VERSION} \
    torch-model-archiver==${TORCHSERVE_VERSION} \
 && ${PIP} install --no-deps --no-cache-dir -U torchvision==0.21.* \
 && rm -rf ~/.cache/pip/*

RUN useradd -m model-server \
 && mkdir -p /home/model-server/tmp /opt/ml/model \
 && chown -R model-server /home/model-server /opt/ml/model

COPY --chmod=755 neuron-entrypoint.py /usr/local/bin/dockerd-entrypoint.py
COPY --chmod=755 neuron-monitor.sh deep_learning_container.py /usr/local/bin/
COPY --chmod=755 torchserve-neuron.sh /usr/local/bin/entrypoint.sh
COPY config.properties /home/model-server

RUN ${PIP} install --no-cache-dir "sagemaker-pytorch-inference==${SM_TOOLKIT_VERSION}" \
 # patch default_pytorch_inference_handler.py to import torch_neuronx
 && DEST_DIR=$(python -c "import os.path, sagemaker_pytorch_serving_container; print(os.path.dirname(sagemaker_pytorch_serving_container.__file__))") \
 && DEST_FILE=${DEST_DIR}/default_pytorch_inference_handler.py \
 && sed -i "s/import torch/import torch, torch_neuronx/" ${DEST_FILE} \
 && rm -rf ~/.cache/pip/*

RUN HOME_DIR=/root \
 && curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \
 && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \
 && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \
 && chmod +x /usr/local/bin/testOSSCompliance \
 && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \
 && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \
 && rm -rf ${HOME_DIR}/oss_compliance* \
 # conda leaves an empty /root/.cache/conda/notices.cache file which is not removed by conda clean -ya
 && rm -rf ${HOME_DIR}/.cache/conda

RUN curl -o /license.txt  https://aws-dlc-licenses.s3.amazonaws.com/pytorch-2.5/license.txt

# Setting up APT and PIP repo for neuron artifacts
ARG NEURON_APT_REPO=https://apt.repos.neuron.amazonaws.com
ARG NEURON_APT_REPO_KEY
ARG NEURON_PIP_REPO=https://pip.repos.neuron.amazonaws.com
ARG NEURON_PIP_REPO_KEY
RUN mkdir -p /etc/apt/keyrings \
 && APT_REPO_PREFIX=$([ -n "${NEURON_APT_REPO_KEY}" ] && echo "${NEURON_APT_REPO_KEY}@" || echo "") \
 && echo "deb [signed-by=/etc/apt/keyrings/neuron.gpg] https://${APT_REPO_PREFIX}${NEURON_APT_REPO} focal main" > /etc/apt/sources.list.d/neuron.list \
 && curl $([ -n "${NEURON_APT_REPO_KEY}" ] && echo "-u ${NEURON_APT_REPO_KEY}") -sSL "https://${NEURON_APT_REPO}/GPG-PUB-KEY-AMAZON-AWS-NEURON.PUB" | gpg --dearmor > /etc/apt/keyrings/neuron.gpg \
 && PIP_REPO_URL=$([ -n "${NEURON_PIP_REPO_KEY}" ] && echo "https://${NEURON_PIP_REPO_KEY}@${NEURON_PIP_REPO}" || echo "https://${NEURON_PIP_REPO}") \
 && ${PIP} config set global.extra-index-url "${PIP_REPO_URL}"

# Neuron SDK components version numbers
ARG NEURON_ARTIFACT_PATH=/root/neuron_artifacts
ARG IGNORE_MISSING_NEURON_COMPONENTS=false
RUN IGNORE_MISSING_NEURON_COMPONENTS=$(echo ${IGNORE_MISSING_NEURON_COMPONENTS} | tr '[:upper:]' '[:lower:]')

ARG NEURONX_COLLECTIVES_LIB_VERSION=2.24.59.0-838c7fc8b
ARG NEURONX_RUNTIME_LIB_VERSION=2.24.53.0-f239092cc
ARG NEURONX_TOOLS_VERSION=2.22.61.0

ARG NEURONX_CC_VERSION=2.17.194.0
ARG NEURONX_FRAMEWORK_VERSION=2.6.0.2.7.0
ARG NEURONX_TRANSFORMERS_VERSION=0.13.470
ARG NEURONX_DISTRIBUTED_VERSION=0.11.0
ARG NEURONX_DISTRIBUTED_INFERENCE_VERSION=0.2.0

FROM base AS dev

RUN --mount=type=bind,source=apt,target=${NEURON_ARTIFACT_PATH}/apt \
    install_apt_package() { \
        pkg_name=$1; \
        version_arg=$2; \
        if [ -f "${NEURON_ARTIFACT_PATH}/apt/${version_arg}" ]; then \
            apt-get install -y ${NEURON_ARTIFACT_PATH}/apt/${version_arg}; \
        elif [ "${IGNORE_MISSING_NEURON_COMPONENTS}" = "false" ]; then \
            apt-get install -y ${pkg_name}=${version_arg}; \
        else \
            echo "Ignoring package ${pkg_name}"; \
        fi; \
    } \
 && apt-get update \
 && install_apt_package "aws-neuronx-collectives" "${NEURONX_COLLECTIVES_LIB_VERSION}" \
 && install_apt_package "aws-neuronx-runtime-lib" "${NEURONX_RUNTIME_LIB_VERSION}" \
 && install_apt_package "aws-neuronx-tools" "${NEURONX_TOOLS_VERSION}" \
 && rm -rf /var/lib/apt/lists/* \
 && rm -rf /tmp/tmp* \
 && apt-get clean

RUN --mount=type=bind,source=pip,target=${NEURON_ARTIFACT_PATH}/pip \
    install_pip_package() { \
        packages=""; \
        flags=""; \
        while [ "$#" -gt 0 ]; do \
            pkg_name=$(echo $1 | cut -d: -f1); \
            version_arg=$(echo $1 | cut -d: -f2); \
            extra_flags=$(echo $1 | cut -d: -f3); \
            if [ -f "${NEURON_ARTIFACT_PATH}/pip/${version_arg}" ]; then \
                packages="${packages} ${NEURON_ARTIFACT_PATH}/pip/${version_arg}"; \
            else \
                if [ "${IGNORE_MISSING_NEURON_COMPONENTS}" = "false" ]; then \
                    packages="${packages} ${pkg_name}==${version_arg}"; \
                else \
                    echo "Ignoring package ${pkg_name}"; \
                fi; \
            fi; \
            # Store unique flags
            if [ ! -z "${extra_flags}" ]; then \
                for flag in $(echo "${extra_flags}" | tr ' ' '\n'); do \
                    case " ${flags} " in \
                        *" ${flag} "*) ;; \
                        *) flags="${flags} ${flag}" ;; \
                    esac \
                done; \
            fi; \
            shift; \
        done; \
        if [ ! -z "${packages}" ]; then \
            echo "Installing packages: ${packages} with flags ${flags}"; \
            ${PIP} install --no-cache-dir \
                --extra-index-url="file:///${NEURON_ARTIFACT_PATH}/pip" \
                ${packages} ${flags}; \
        fi; \
    } \
 && install_pip_package "neuronx-cc:${NEURONX_CC_VERSION}:" "torch-neuronx:${NEURONX_FRAMEWORK_VERSION}:" \
 && install_pip_package "transformers-neuronx:${NEURONX_TRANSFORMERS_VERSION}:" \
 && install_pip_package "neuronx_distributed:${NEURONX_DISTRIBUTED_VERSION}:--no-deps" \
 && install_pip_package "neuronx_distributed_inference:${NEURONX_DISTRIBUTED_INFERENCE_VERSION}:--no-deps" \
 && rm -rf ~/.cache/pip/*

 FROM base AS repo

 # Install Neuron components from the apt and pip repos 
 RUN apt-get update \
 && apt-get install -y \
    aws-neuronx-tools \
    aws-neuronx-collectives \
    aws-neuronx-runtime-lib \
 && pip install --no-cache-dir \
    neuronx-cc \
    torch-neuronx \
    transformers-neuronx \
 && pip install --no-cache-dir --no-deps \
    neuronx_distributed \
    neuronx_distributed_inference \
 && rm -rf /var/lib/apt/lists/* \
 && rm -rf /tmp/tmp* \
 && rm -rf ~/.cache/pip/* \
 && apt-get clean

FROM base AS prod

RUN apt-get update \
 && apt-get install -y \
    aws-neuronx-tools=$NEURONX_TOOLS_VERSION \
    aws-neuronx-collectives=$NEURONX_COLLECTIVES_LIB_VERSION \
    aws-neuronx-runtime-lib=$NEURONX_RUNTIME_LIB_VERSION \
 && rm -rf /var/lib/apt/lists/* \
 && rm -rf /tmp/tmp* \
 && apt-get clean

RUN pip install --no-cache-dir \
   neuronx-cc==$NEURONX_CC_VERSION \
   torch-neuronx==$NEURONX_FRAMEWORK_VERSION \
   transformers-neuronx==$NEURONX_TRANSFORMERS_VERSION \ 
 && pip install --no-cache-dir --no-deps \
    neuronx_distributed==$NEURONX_DISTRIBUTED_VERSION \
    neuronx_distributed_inference==$NEURONX_DISTRIBUTED_INFERENCE_VERSION \
 && rm -rf ~/.cache/pip/*

FROM ${BUILD_STAGE} AS final

EXPOSE 8080 8081

ENTRYPOINT ["python", "/usr/local/bin/dockerd-entrypoint.py"]
CMD ["/usr/local/bin/entrypoint.sh"]

HEALTHCHECK CMD curl --fail http://localhost:8080/ping || exit 1